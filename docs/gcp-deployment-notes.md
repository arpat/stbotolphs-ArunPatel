# Cloud Deployment Notes

You will find initial work for a Google Cloud Platform (GCP)deployment of this website
in the `deploy/` directory. There are still some outstanding tasks requiring configuration
and testing before being considered complete. They are listed below. As the site has an integration with Amazon Web Services (AWS) for an S3 object store, an account with AWS is also required.

## Terraform

The Cloud infrastructure is configured and deployed by the Terraform tool from Hashicorp, which I believe you are familiar with.

The `deploy/` directory contains terraform modules in a subdirectory and seperate directories for instances of the application, known as environments. The `modules/` directory contains subdirectories of terraform code, which create cloud infrastructure when called from executing terrafrom from the environment (or root) directories. Terraform configuration pertinent to an environment should exist in each environment directory allowing you to tune each environment seperately.

### Deploying to the Cloud

This [document](https://cloud.google.com/recommender/docs/tutorial-iac) may be a good start if you have not used Terrafrom GCP before. The deployment is built around GCP Cloud Build, Cloud Run, Cloud SQL and AWS S3.

Ensure you have at least terraform version 0.12.

Authenticate to GCP using `gcloud auth application-default login`, alternatively follow instructions [here.](https://registry.terraform.io/providers/hashicorp/google/latest/docs/guides/getting_started)

Authenticate to AWS. 

`cd deploy/prod`  or the environment of choice.

`terraform init`  and wait for the initialization to complete.

`terraform fmt && terraform validate && terraform plan -out planfile`

A plan of the deployment should be presented to you, please check it meets expectations before proceeding.

`terraform apply planfile` this may take some time.

Infrastructure should appear for you in GCP (and AWS), you may confirm by using the cloud console.

## Updating the Application

GCP Cloud Build is utilised to build and deploy your application upon a trigger generated by Github on a push to master (or other branch). The initial connection between Cloud Build and Github needs to happen once and is a manual operation through the console, as described [here](https://cloud.google.com/cloud-build/docs/automating-builds/create-github-app-triggers). After that completes, further configuration should be done with terraform in `modules/cloud-build/`

## Managing Secrets

When run initially, the database will need to be created before a user and password can be genreated through the console (further information [here](https://cloud.google.com/sql/docs/postgres/create-manage-users)) and stolred locally, securely.

Powerless strings can be used in place of secrets just to get infrastructure built. Plaintext secrets in environment variables on Cloud Run is discouraged for anything other than basic testing.

Genuine secrets will need to be encrypted with the GCP KMS service.

```
echo -n secret-password | gcloud kms encrypt  \
    --project stbotolphs-297814  \
    --location europe-west1  \
    --keyring main-keyring  \
    --key sql-crypto-key  \
    --plaintext-file -  \
    --ciphertext-file -  | base64 -w
```

And the encrypted result used in place of the usual DJANGO_DB_PASSWORD like environmet variables, which requires some code to decrypt it on-the-fly once at launch time on the Cloud. 

The database and AWS encrypted secrets are passed as `TF_VAR_` environment variables when terraform is run locally.

eg: `export TF_VAR_django_db_password=xxxxxxxxxxxxxxxx`

## Service Accounts

Initial builds of infrastruture may utilise _owner_/_editor_ or other admin roles however, dedicated service accounts should be created and restricted to the minimal privilages. Futher configuration will be needed so that only these service accounts are used by Cloud Run or human operators in day-to-day work.

## CICD

GCP Cloud build is used to build and deploy the application. It is also possible that once the infrastructure is built and operating correctly, another build can be created for the Terraform deployment actions. 

## Alerting and Monitoring

GCP Stack driver should be utilised for site monitoring and alerting. A range of integrations are avaliable such as Slack and Pagerduty.

## Vendor Lock-In

It is unlikely that a near like-for-like migration to an alternate cloud provider will be difficult to achieve. AWS RDS for example can replace Cloud SQL, and `pip install django-storages[google]` may be able to replace AWS S3.

Terraform plays well under these circumstances and can make the transition easy to plan.

## Outstanding Tasks

- Complete Terraform modules
- Complete Terraform environment (at least two)
- Get KMS application integration working
- Fix the Minio/S3 issue with images (`boto3` version issue?)
- Create Service Accounts in Terraform for Cloud Run
- Create Service Accounts for Operators (impersonation)
- Create instructions for Cloud SQL Proxy for developer use
- Create Terraform config for the S3 Bucket Policy